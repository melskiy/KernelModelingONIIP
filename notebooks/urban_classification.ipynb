{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи поиска аномалий, была рассмотрена вспомогательная задача классификации звуков города из датасета \"UrbanSound\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет составлен с помощью *APi* Youtube8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/urban/UrbanSound8K.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = []\n",
    "for i in range(1,11):\n",
    "    appended.append(data[data.fold == i]['class'].value_counts())\n",
    "    \n",
    "class_distribution = pd.DataFrame(appended)\n",
    "class_distribution = class_distribution.reset_index()\n",
    "class_distribution['index'] = [\"fold\"+str(x) for x in range(1,11)]\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "from scipy.io import wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "def path_class(filename):\n",
    "    excerpt = data[data['slice_file_name'] == filename]\n",
    "    path_name = os.path.join('../data/urban/', 'fold'+str(excerpt.fold.values[0]), filename)\n",
    "    return path_name, excerpt['class'].values[0]\n",
    "\n",
    "def wav_plotter(full_path, class_label):   \n",
    "    rate, wav_sample = wav.read(full_path)\n",
    "    wave_file = open(full_path,\"rb\")\n",
    "    riff_fmt = wave_file.read(36)\n",
    "    bit_depth_string = riff_fmt[-2:]\n",
    "    bit_depth = struct.unpack(\"H\",bit_depth_string)[0]\n",
    "    print('sampling rate: ',rate,'Hz')\n",
    "    print('bit depth: ',bit_depth)\n",
    "    print('number of channels: ',wav_sample.shape[1])\n",
    "    print('duration: ',wav_sample.shape[0]/rate,' second')\n",
    "    print('number of samples: ',len(wav_sample))\n",
    "    print('class: ',class_label)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(wav_sample) \n",
    "    return ipd.Audio(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullpath, label = path_class('100263-2-0-117.wav')\n",
    "wav_plotter(fullpath,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('../data/urban/fold1/7383-3-0-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class = data.value_counts()\n",
    "f, ax = plt.subplots(figsize=(18,5)) \n",
    "ax = sns.countplot(x=data['class'], data=data['class'])\n",
    "plt.title('Class Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "классы *car_horn* и *gun_shot* имеют меньшее число объектов по отношению к другим классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из методов апроксимации звукового сигнала является метод наименьших квадратов, он помогает удалять шумы и представлять звуковой сигнал в виде комбинации полиноминальных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyCoefficients(x, coeffs):\n",
    "    o = len(coeffs)\n",
    "    print(f'# This is a polynomial of order {ord}.')\n",
    "    y = 0\n",
    "    for i in range(o):\n",
    "        y += coeffs[i]*(x**i)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,sr*4,sr*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.polyfit(x, y,25)\n",
    "coeffs = np.flip(coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(x, PolyCoefficients(x, coeffs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрев полиномы степеней 1,2,3...25, пришли к выводу, что данный метод не подходит для представления нашего звукового сигнала, так как звук имеет хаотичный характер, и следовательно его нельзя описать с помощью полиномов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее были рассмотренны более сложные методы, такие как вейвлет преобразования. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_wavelets = ['db5', 'sym5', 'coif5', 'haar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "st='haar'\n",
    "(cA, cD) = pywt.dwt(y,st)\n",
    "subplot(2, 1, 1)\n",
    "plot(cA,'b',linewidth=2, label='cA,level-1')\n",
    "grid()\n",
    "legend(loc='best')\n",
    "subplot(2, 1, 2)\n",
    "plot(cD,'r',linewidth=2, label='cD,level-1')\n",
    "grid()\n",
    "legend(loc='best')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперименты с ядром вейвлет функции, не дали ощутимых результатов, поэтому нет сильной разницы в его выборе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также были рассмотрено несколько уровней вейвлет преобразования, после каждого такого уровня, длинна звуковой дорожки уменьшается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=cA, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=cD, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cA, cD) = pywt.dwt(y,st)\n",
    "(cA, cD) = pywt.dwt(cA,st)\n",
    "(cA, cD) = pywt.dwt(cA,st)\n",
    "(cA, cD) = pywt.dwt(cA,st)\n",
    "(cA, cD) = pywt.dwt(cA,st)\n",
    "subplot(2, 1, 1)\n",
    "plot(cA,'b',linewidth=2, label='cA,level-5')\n",
    "grid()\n",
    "legend(loc='best')\n",
    "subplot(2, 1, 2)\n",
    "plot(cD,'r',linewidth=2, label='cD,level-5')\n",
    "grid()\n",
    "legend(loc='best')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как итог, вейвлет преобразование помогает хорошо описать сигнал, экономя пространство на диске и сохраняя нужную информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=cA, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=cD, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В звук можно добавить шум, чтобы расширить количество объектов и протестировать методы, которые борятся с шумом и помехами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(len(y))\n",
    "data_noise = y + 0.005 * noise\n",
    "ipd.Audio(data=data_noise, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_third = librosa.effects.pitch_shift(y =y,sr = sr, n_steps=20)\n",
    "ipd.Audio(data=y_third, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем на практике применить фильтр Калмана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KalmanFilter(transition_matrices=np.array([[1, 1], [0, 1]]),\n",
    "                  transition_covariance=0.01 * np.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "observations = data_noise\n",
    "x = np.linspace(0,sr*4,sr*4)\n",
    "\n",
    "filtered_state_estimates = kf.filter(observations)\n",
    "smoothed_state_estimates = kf.smooth(observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_state_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_state_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(x,filtered_state_estimates[0][:,0])\n",
    "plt.plot(x,filtered_state_estimates[0][:,1],c = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=filtered_state_estimates[0][:,1], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=smoothed_state_estimates[0][:,1], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрели пороговые методы фильтрации частот, lowpass - фильтр нижних частот, highpass - фильтр высоких частот, bandpass - полосовой фильтр, bandstop - заграждающий фильтр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    " \n",
    "b, a = signal.butter(5, 0.1, 'lowpass')   \n",
    "filtedData = signal.filtfilt(b, a, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(y)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(filtedData)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=filtedData, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, a = signal.butter(8, 0.2, 'highpass')   \n",
    "filtedData2 = signal.filtfilt(b, a, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(filtedData2)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=filtedData2, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    " \n",
    "b, a = signal.butter(8, [0.1,0.6], 'bandpass')  \n",
    "filtedData3 = signal.filtfilt(b, a,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(filtedData3)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=filtedData3, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, a = signal.butter(8, [0.2,0.8], 'bandstop')   \n",
    "filtedData4 = signal.filtfilt(b, a, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(filtedData4)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=filtedData4, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_melspec(filename,name,dirr):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, duration=2.97)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate,n_fft=2048, hop_length=512)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = Path('../data/melspec/' + dirr +'/' +name + '.jpg')\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8732 entries, 0 to 8731\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   slice_file_name  8732 non-null   object \n",
      " 1   fsID             8732 non-null   int64  \n",
      " 2   start            8732 non-null   float64\n",
      " 3   end              8732 non-null   float64\n",
      " 4   salience         8732 non-null   int64  \n",
      " 5   fold             8732 non-null   int64  \n",
      " 6   classID          8732 non-null   int64  \n",
      " 7   class            8732 non-null   object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 545.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['100032-3-0-0.wav', 100032, 0.0, ..., 5, 3, 'dog_bark'],\n",
       "       ['100263-2-0-117.wav', 100263, 58.5, ..., 5, 2,\n",
       "        'children_playing'],\n",
       "       ['100263-2-0-121.wav', 100263, 60.5, ..., 5, 2,\n",
       "        'children_playing'],\n",
       "       ...,\n",
       "       ['99812-1-4-0.wav', 99812, 242.691902, ..., 7, 1, 'car_horn'],\n",
       "       ['99812-1-5-0.wav', 99812, 253.20985, ..., 7, 1, 'car_horn'],\n",
       "       ['99812-1-6-0.wav', 99812, 332.289233, ..., 7, 1, 'car_horn']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../data/melspec/'\n",
    "  \n",
    "list = data['class'].unique()\n",
    "  \n",
    "for items in list:\n",
    "    path = os.path.join(root_path, items)\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\malya\\Desktop\\kernelModeling\\KernelModelingONIIP\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "c:\\Users\\malya\\Desktop\\kernelModeling\\KernelModelingONIIP\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "c:\\Users\\malya\\Desktop\\kernelModeling\\KernelModelingONIIP\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "c:\\Users\\malya\\Desktop\\kernelModeling\\KernelModelingONIIP\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "c:\\Users\\malya\\Desktop\\kernelModeling\\KernelModelingONIIP\\venv\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in data.values:\n",
    "    filename = '../data/urban/fold' + str(i[5]) + '/' + str(i[0])\n",
    "    name = str(i[0])\n",
    "    dirr = str(i[-1])\n",
    "    create_melspec(filename,name,dirr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8732 files belonging to 10 classes.\n",
      "Using 6986 files for training.\n",
      "Using 1746 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../data/melspec\", \n",
    "    validation_split=0.2, \n",
    "    subset=\"both\", \n",
    "    seed=42, \n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользовались мел-спектограммами для того, чтобы обучить сверточную нейронную сеть и классифицировать звуки, предоставленные в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(128, 4, strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 104s 466ms/step - loss: 1.5866 - accuracy: 0.4572 - val_loss: 1.2146 - val_accuracy: 0.5922\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 79s 362ms/step - loss: 0.9209 - accuracy: 0.6891 - val_loss: 0.9219 - val_accuracy: 0.6930\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 84s 384ms/step - loss: 0.6865 - accuracy: 0.7803 - val_loss: 0.8978 - val_accuracy: 0.7228\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 98s 448ms/step - loss: 0.5317 - accuracy: 0.8267 - val_loss: 0.7370 - val_accuracy: 0.7732\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 80s 362ms/step - loss: 0.3941 - accuracy: 0.8739 - val_loss: 0.6186 - val_accuracy: 0.8230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d47330cbe0>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=5, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143667240 (548.05 MB)\n",
      "Trainable params: 143667240 (548.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = tf.keras.applications.VGG19(weights='imagenet', include_top=True)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = vgg.input\n",
    "\n",
    "new_classification_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "\n",
    "model_new = tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_new.layers:\n",
    "    layer.trainable = False\n",
    "model_new.layers[-1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139611210 (532.57 MB)\n",
      "Trainable params: 40970 (160.04 KB)\n",
      "Non-trainable params: 139570240 (532.42 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1287s 6s/step - loss: 1.0159 - accuracy: 0.6685 - val_loss: 0.7591 - val_accuracy: 0.7635\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 1272s 6s/step - loss: 0.5947 - accuracy: 0.8030 - val_loss: 0.6739 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 1143s 5s/step - loss: 0.4675 - accuracy: 0.8418 - val_loss: 0.6756 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 1254s 6s/step - loss: 0.3888 - accuracy: 0.8654 - val_loss: 0.6126 - val_accuracy: 0.8058\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 1338s 6s/step - loss: 0.3376 - accuracy: 0.8859 - val_loss: 0.5578 - val_accuracy: 0.8207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d48c8cf580>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.fit(train_ds, epochs=5, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 220s 4s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_ds = model_new.predict(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.76      0.81       199\n",
      "         1.0       0.90      0.64      0.75        73\n",
      "         2.0       0.72      0.86      0.78       198\n",
      "         3.0       0.85      0.75      0.80       207\n",
      "         4.0       0.88      0.79      0.83       198\n",
      "         5.0       0.78      0.93      0.85       218\n",
      "         6.0       0.99      0.86      0.92        78\n",
      "         7.0       0.79      0.94      0.86       171\n",
      "         8.0       0.93      0.82      0.87       217\n",
      "         9.0       0.73      0.76      0.74       187\n",
      "\n",
      "    accuracy                           0.82      1746\n",
      "   macro avg       0.84      0.81      0.82      1746\n",
      "weighted avg       0.83      0.82      0.82      1746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = [np.argmax(pred) for pred in y_pred_ds]\n",
    "\n",
    "y_test = np.array([])\n",
    "\n",
    "images, labels = tuple(zip(*test_ds))\n",
    "for i in labels:\n",
    "    y_test = np.append(y_test, i)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 7s 124ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_ds2 = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.91      0.79       199\n",
      "         1.0       0.98      0.84      0.90        73\n",
      "         2.0       0.83      0.51      0.63       198\n",
      "         3.0       0.74      0.87      0.80       207\n",
      "         4.0       0.91      0.83      0.87       198\n",
      "         5.0       0.92      0.88      0.90       218\n",
      "         6.0       0.97      0.94      0.95        78\n",
      "         7.0       0.90      0.85      0.87       171\n",
      "         8.0       0.88      0.88      0.88       217\n",
      "         9.0       0.67      0.80      0.73       187\n",
      "\n",
      "    accuracy                           0.82      1746\n",
      "   macro avg       0.85      0.83      0.83      1746\n",
      "weighted avg       0.83      0.82      0.82      1746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = [np.argmax(pred) for pred in y_pred_ds2]\n",
    "\n",
    "y_test = np.array([])\n",
    "\n",
    "images, labels = tuple(zip(*test_ds))\n",
    "for i in labels:\n",
    "    y_test = np.append(y_test, i)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге модель, обученная с помощью TransferLearning показала разницу в точности несравнимую с скоростью получения предсказания, поэтому в переспективе стоит остановиться на моделях собсвенной архитектуры"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
